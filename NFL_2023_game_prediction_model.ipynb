{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nfl_data_py as nfl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silences pandas warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update Elo rating after a match\n",
    "def update_elo(player1_elo, player2_elo, result, k_factor=32):\n",
    "    expected_score_player1 = 1 / (1 + 10 ** ((player2_elo - player1_elo) / 400))\n",
    "    expected_score_player2 = 1 - expected_score_player1\n",
    "\n",
    "    player1_new_elo = player1_elo + k_factor * (result - expected_score_player1)\n",
    "    player2_new_elo = player2_elo + k_factor * ((1 - result) - expected_score_player2)\n",
    "\n",
    "    return player1_new_elo, player2_new_elo\n",
    "\n",
    "# Function to regress Elo ratings towards the mean\n",
    "def regress_to_mean(elo_ratings, mean_elo, regression_weight=1/3):\n",
    "    elo_ratings['Elo'] = elo_ratings['Elo'] + regression_weight * (mean_elo - elo_ratings['Elo'])\n",
    "    return elo_ratings \n",
    "\n",
    "# Function to calculate mean Elo\n",
    "def calculate_mean_elo(elo_ratings):\n",
    "    return elo_ratings.Elo.sum() / len(elo_ratings)\n",
    "\n",
    "def get_elo(team,season,week,df):\n",
    "    try:\n",
    "        elo = [df.loc[(df['Team']==team)&(df['Season']==season)&(df['Week']==week-1)], 'Elo'].values[0]\n",
    "    except:\n",
    "        team_week = df.loc[(df['Team']==team)&(df['Season']==season)&(df['Week']<week)]['Week'].max()\n",
    "        elo = df.loc[(df['Team']==team)&(df['Season']==season)&(df['Week']==team_week), 'Elo'].values[0]   \n",
    "    return elo\n",
    "\n",
    "def get_qb_elo(qb_id,season,week,historical_elo_qb):\n",
    "    '''\n",
    "    This function will grab the specific elo rating of a QB from a specific season and week\n",
    "    '''\n",
    "    if week == 1:\n",
    "        try:\n",
    "            qb_week = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==season-1)]['Week'].max()\n",
    "            elo = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==season-1)&(historical_elo_qb['Week']==qb_week), 'Elo'].values[0]\n",
    "        except:\n",
    "            try:\n",
    "                qb_season = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']<season)]['Season'].max()\n",
    "                qb_week = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==qb_season)]['Week'].max()\n",
    "                elo = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==qb_season)&(historical_elo_qb['Week']==qb_week), 'Elo'].values[0]\n",
    "            except:\n",
    "                elo = 1500\n",
    "    else:\n",
    "        try:\n",
    "            elo = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==season)&(historical_elo_qb['Week']==week-1), 'Elo'].values[0]\n",
    "        except:\n",
    "            try:\n",
    "                qb_week = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==season)&(historical_elo_qb['Week']<week)]['Week'].max()\n",
    "                elo = historical_elo_qb.loc[(historical_elo_qb['passer_id']==row['home_qb_id'])&(historical_elo_qb['Season']==season)&(historical_elo_qb['Week']==qb_week), 'Elo'].values[0]\n",
    "            except:\n",
    "                try:\n",
    "                    qb_season = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']<season)]['Season'].max()\n",
    "                    qb_week = historical_elo_qb.loc[(historical_elo_qb['passer_id']==qb_id)&(historical_elo_qb['Season']==qb_season)]['Week'].max()\n",
    "                    elo = historical_elo_qb.loc[(historical_elo_qb['passer_id']==row['home_qb_id'])&(historical_elo_qb['Season']==qb_season)&(historical_elo_qb['Week']==qb_week), 'Elo'].values[0]\n",
    "                except:\n",
    "                    elo = 1500\n",
    "    \n",
    "    return elo\n",
    "\n",
    "def get_value(df, season, week, team, team_col_name, num, denom):\n",
    "    '''Get weighted average of stats over the last two seasons'''\n",
    "    df_temp = df.loc[(df['season']==season)&(df['week']<week)&(df[team_col_name]==team)]\n",
    "    df_temp2 = df.loc[(df['season']==season-1)&(df[team_col_name]==team)]\n",
    "    value2 = df_temp2[num].sum()/df_temp2[denom].sum()\n",
    "    if df_temp[denom].sum() == 0:\n",
    "        return value2\n",
    "    value = df_temp[num].sum()/df_temp[denom].sum()\n",
    "    if week == 1:\n",
    "        final_value = value2\n",
    "    elif week > 12:\n",
    "        final_value = value\n",
    "    else:\n",
    "        final_value = week*value/12 + (12-week)*value2/12\n",
    "\n",
    "    if final_value is None:\n",
    "        return value2\n",
    "    else:\n",
    "        return final_value\n",
    "\n",
    "def get_qbr(df, season, week, qb_id):\n",
    "    '''Get weighted average of QBR over the last two seasons'''\n",
    "    df_temp = df.loc[(df['season']==season)&(df['game_week']<week)&(df['gsis_id']==qb_id)]\n",
    "    if len(df_temp)>0:\n",
    "        df_temp['weighted'] = df_temp['qbr_total']*df_temp['qb_plays']/df_temp['qb_plays'].sum()\n",
    "        value = df_temp['weighted'].sum()\n",
    "    else:\n",
    "        value = 50.0\n",
    "    \n",
    "    df_temp2 = df.loc[(df['season']==season-1)&(df['gsis_id']==qb_id)]\n",
    "    if len(df_temp2) > 0:\n",
    "        df_temp2['weighted'] = df_temp2['qbr_total']*df_temp2['qb_plays']/df_temp2['qb_plays'].sum()\n",
    "        value2 = df_temp2['weighted'].sum()\n",
    "    else:\n",
    "        value2 = 50.0\n",
    "    if week == 1:\n",
    "        final_value = value2\n",
    "    elif week > 12:\n",
    "        final_value = value\n",
    "    else:\n",
    "        final_value = week*value/12 + (12-week)*value2/12\n",
    "    \n",
    "    return final_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [year for year in range(1999, 2023)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_data = nfl.import_weekly_data(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups = nfl.import_schedules(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchups.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming = nfl.import_schedules([2023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qbr = nfl.import_qbr([year for year in range(2007, 2023)], level='nfl', frequency='weekly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nfl.import_pbp_data([year for year in range(1999, 2023)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all relocated teams\n",
    "replace_dict = {'OAK':'LV','STL':'LA','SD':'LAC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace any relocated teams\n",
    "data['home_team'] = data['home_team'].replace(replace_dict)\n",
    "data['away_team'] = data['away_team'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass_att = data.loc[data['play_type']=='pass']\n",
    "pass_att = data.loc[data['play_type_nfl']=='PASS']\n",
    "rush_att = data.loc[data['play_type']=='rush']\n",
    "plays = data.loc[data['play']==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_stats = pass_att.pivot_table(index=['passer_id','passer','season','season_type','week','game_id','game_date','posteam','defteam'], values=['play_id','incomplete_pass','yards_gained','interception', \\\n",
    "    'pass_touchdown'], aggfunc={'play_id':'count', 'incomplete_pass': 'sum','yards_gained': 'sum','interception': 'sum','pass_touchdown': 'sum',}).reset_index().sort_values(by='play_id', \\\n",
    "        ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create passer rating\n",
    "pass_stats.loc[:,'completion_pct'] = 1-(pass_stats.loc[:,'incomplete_pass']+pass_stats.loc[:,'interception'])/pass_stats.loc[:,'play_id']\n",
    "pass_stats.loc[:,'yards_per_att'] = pass_stats.loc[:,'yards_gained']/pass_stats.loc[:,'play_id']\n",
    "pass_stats.loc[:,'td_per_att'] = pass_stats.loc[:,'pass_touchdown']/pass_stats.loc[:,'play_id']\n",
    "pass_stats.loc[:,'int_per_att'] = pass_stats.loc[:,'interception']/pass_stats.loc[:,'play_id']\n",
    "pass_stats.loc[:,'a'] = np.where((5*(pass_stats.loc[:,'completion_pct']-0.3)<=2.375)&(5*(pass_stats.loc[:,'completion_pct']-0.3)>=0), 5*(pass_stats.loc[:,'completion_pct']-0.3), \\\n",
    "    np.where((5*(pass_stats.loc[:,'completion_pct']-0.3)>2.375), 2.375, 0))\n",
    "pass_stats.loc[:,'b'] = np.where(((0.25*(pass_stats.loc[:,'yards_per_att']-3))<=2.375)&((0.25*(pass_stats.loc[:,'yards_per_att']-3))>=0), (0.25*(pass_stats.loc[:,'yards_per_att']-3)), \\\n",
    "    np.where(((0.25*(pass_stats.loc[:,'yards_per_att']-3))>2.375), 2.375, 0))\n",
    "pass_stats.loc[:,'c'] = np.where(((20*pass_stats.loc[:,'td_per_att'])<=2.375)&((20*pass_stats.loc[:,'td_per_att'])>=0), (20*pass_stats.loc[:,'td_per_att']), \\\n",
    "    np.where(((20*pass_stats.loc[:,'td_per_att'])>2.375), 2.375, 0))\n",
    "pass_stats.loc[:,'d'] = np.where(((2.375-(25*pass_stats.loc[:,'int_per_att']))<=2.375)&((2.375-(25*pass_stats.loc[:,'int_per_att']))>=0), (2.375-(25*pass_stats.loc[:,'int_per_att'])), \\\n",
    "    np.where(((2.375-(25*pass_stats.loc[:,'int_per_att']))>2.375), 2.375, 0))\n",
    "pass_stats.loc[:,'passer_rating'] = 100*((pass_stats.loc[:,'a']+pass_stats.loc[:,'b']+pass_stats.loc[:,'c']+pass_stats.loc[:,'d'])/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 10 pass attempts\n",
    "pass_stats = pass_stats.loc[pass_stats['play_id']>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_stats = pass_stats.sort_values(by='game_date').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for season change\n",
    "pass_stats['season_shift'] = pass_stats['season'].shift().fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial elo rating\n",
    "initial_elo = 1500\n",
    "\n",
    "# Create a dictionary to hold current Elo ratings for each player\n",
    "qb_ratings = {player: initial_elo for player in pass_stats['passer_id'].unique()}\n",
    "def_ratings = {team: initial_elo for team in pass_stats['defteam'].unique()}\n",
    "\n",
    "# Create a separate DataFrame to store the updated Elo ratings\n",
    "elo_qb = pd.DataFrame(qb_ratings.items(), columns=['passer_id', 'Elo'])\n",
    "elo_qb = elo_qb.merge(pass_stats[['passer_id', 'passer']].drop_duplicates(), how='inner', on='passer_id')\n",
    "elo_def = pd.DataFrame(def_ratings.items(), columns=['Team', 'Elo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to hold historical weekly Elo ratings for each team and QB\n",
    "historical_elo_def = pd.DataFrame(columns=['Team', 'Season', 'Week', 'Elo'])\n",
    "historical_elo_qb = pd.DataFrame(columns=['passer_id', 'Passer', 'Season', 'Week', 'Elo'])\n",
    "\n",
    "# Iterate through matchups DataFrame and update Elo ratings\n",
    "for index, row in pass_stats.iterrows():\n",
    "\n",
    "    # Check if the season has ended (you need to define the condition for season end)\n",
    "    if (row['season_shift']!=0.0) & (row['season'] != row['season_shift']):\n",
    "        \n",
    "        # Calculate mean Elo at the end of the season\n",
    "        mean_elo = calculate_mean_elo(elo_def)\n",
    "\n",
    "        # Regress each team's Elo ratings towards the mean\n",
    "        elo_def = regress_to_mean(elo_def, mean_elo, regression_weight=1/3)\n",
    "        \n",
    "        elo_def_temp = elo_def.copy()\n",
    "        \n",
    "        elo_def_temp['Week'] = 0\n",
    "        elo_def_temp['Season'] = row['season']\n",
    "        \n",
    "        historical_elo_def = pd.concat([historical_elo_def,elo_def_temp])\n",
    "    \n",
    "    player1 = row['passer_id']\n",
    "    player2 = row['defteam']\n",
    "    result = 1 if row['passer_rating'] >= pass_stats.loc[pass_stats.season==row['season']].passer_rating.median() else 0 ## A passer rating above season median is considered a win for the QB\n",
    "\n",
    "    player1_elo = elo_qb.loc[elo_qb['passer_id']==row['passer_id']].reset_index().loc[0,'Elo']\n",
    "    player2_elo = elo_def.loc[elo_def['Team']==row['defteam']].reset_index().loc[0,'Elo']\n",
    "\n",
    "    player1_new_elo, player2_new_elo = update_elo(player1_elo, player2_elo, result)\n",
    "    \n",
    "    elo_qb.loc[elo_qb['passer_id'] == row['passer_id'], 'Elo'] = player1_new_elo\n",
    "    elo_def.loc[elo_def['Team'] == row['defteam'], 'Elo'] = player2_new_elo\n",
    "    \n",
    "    # Append the updated Elo ratings to the historical Elo DataFrame\n",
    "    historical_elo_qb = pd.concat([\n",
    "        historical_elo_qb,\n",
    "        pd.DataFrame([{'passer_id': row['passer_id'], 'Passer': row['passer'], 'Season': row['season'], 'Week': row['week'], 'Elo': player1_new_elo}])\n",
    "    ])\n",
    "    historical_elo_def = pd.concat([\n",
    "        historical_elo_def,\n",
    "        pd.DataFrame([{'Team': row['defteam'], 'Season': row['season'], 'Week': row['week'], 'Elo': player2_new_elo}])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold current Elo ratings for each team\n",
    "elo_ratings = {team: initial_elo for team in pd.concat([matchups['away_team'], matchups['home_team']]).unique()}\n",
    "\n",
    "# Step 3: Create a separate DataFrame to store the updated Elo ratings\n",
    "elo_df = pd.DataFrame(elo_ratings.items(), columns=['Team', 'Elo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace team names\n",
    "matchups['away_team'] = matchups['away_team'].replace(replace_dict)\n",
    "matchups['home_team'] = matchups['home_team'].replace(replace_dict)\n",
    "matchups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check for season change\n",
    "matchups['season_shift'] = matchups['season'].shift().fillna(0.0)\n",
    "\n",
    "# Create a new DataFrame to hold historical weekly Elo ratings for each team\n",
    "historical_elo_df = pd.DataFrame(columns=['Team', 'Season', 'Week', 'Elo'])\n",
    "\n",
    "# Iterate through matchups DataFrame and update Elo ratings\n",
    "for index, row in matchups.iterrows():\n",
    "    # Check if the season has ended (you need to define the condition for season end)\n",
    "    if (row['season_shift']!=0.0) & (row['season'] != row['season_shift']):\n",
    "        \n",
    "        # Calculate mean Elo at the end of the season\n",
    "        mean_elo = calculate_mean_elo(elo_df)\n",
    "\n",
    "        # Regress each team's Elo ratings towards the mean\n",
    "        elo_df = regress_to_mean(elo_df, mean_elo, regression_weight=1/3)\n",
    "        \n",
    "        elo_df_temp = elo_df.copy()\n",
    "        \n",
    "        elo_df_temp['Week'] = 0\n",
    "        elo_df_temp['Season'] = row['season']\n",
    "        \n",
    "        historical_elo_df = pd.concat([historical_elo_df,elo_df_temp])\n",
    "    \n",
    "    if row['result'] < 0:\n",
    "        result = 1\n",
    "    elif row['result'] == 0:\n",
    "        result = 0.5\n",
    "    else:\n",
    "        result = 0\n",
    "\n",
    "    player1_elo = elo_df.loc[elo_df['Team']==row['away_team']].reset_index().loc[0,'Elo']\n",
    "    player2_elo = elo_df.loc[elo_df['Team']==row['home_team']].reset_index().loc[0,'Elo']\n",
    "\n",
    "    player1_new_elo, player2_new_elo = update_elo(player1_elo, player2_elo, result)\n",
    "    \n",
    "    # Update the main Elo DataFrame with the updated Elo ratings\n",
    "    elo_df.loc[elo_df['Team'] == row['away_team'], 'Elo'] = player1_new_elo\n",
    "    elo_df.loc[elo_df['Team'] == row['home_team'], 'Elo'] = player2_new_elo\n",
    "    \n",
    "    # Append the updated Elo ratings to the historical Elo DataFrame\n",
    "    historical_elo_df = pd.concat([\n",
    "        historical_elo_df,\n",
    "        pd.DataFrame([{'Team': row['away_team'], 'Season': row['season'], 'Week': row['week'], 'Elo': player1_new_elo}]),\n",
    "        pd.DataFrame([{'Team': row['home_team'], 'Season': row['season'], 'Week': row['week'], 'Elo': player2_new_elo},])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress each team's Elo ratings towards the mean\n",
    "elo_def = regress_to_mean(elo_def, calculate_mean_elo(elo_def), regression_weight=1/3)\n",
    "elo_df = regress_to_mean(elo_df, calculate_mean_elo(elo_df), regression_weight=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace team names\n",
    "weekly_data['recent_team'] = weekly_data['recent_team'].replace(replace_dict)\n",
    "weekly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table of weekly team metrics\n",
    "weekly_sum = weekly_data.pivot_table(index=['season','week','recent_team'], values=['carries','rushing_yards','rushing_epa',\\\n",
    "    'passing_epa','attempts','sacks'], aggfunc='sum').reset_index().sort_values(by=['season','week'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify if there was a turnover in a drive/ how many points scored\n",
    "data['drive_turnover'] = np.where(data['fixed_drive_result'].isin(['Turnover','Opp touchdown']), 1.0, 0.0)\n",
    "data['drive_points'] = np.where(data['fixed_drive_result']=='Touchdown', 6.0, np.where(data['fixed_drive_result']=='Field goal', 3.0, np.where(data['fixed_drive_result']=='Safety', -2.0, 0.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any NA plays\n",
    "drive_df = data.loc[~data['drive_play_count'].isna()].drop_duplicates(subset=['game_id','fixed_drive'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab yardage, 3rd and 4th down conversions, drive success rates, epa, drive turnover rates, redzone conversion, QBR\n",
    "off_yardage = data.pivot_table(index=['season','week','posteam','defteam'], values=['yards_gained','play','third_down_converted','third_down_failed','fourth_down_converted','fourth_down_failed',\\\n",
    "    'epa'], aggfunc='sum').reset_index().sort_values(by=['season','week'], ascending=False)\n",
    "drive_data = drive_df.pivot_table(index=['season','week','posteam','defteam'], values=['fixed_drive','drive_points','drive_turnover','drive_play_count','drive_first_downs','drive_inside20',\\\n",
    "    'drive_yards_penalized'], aggfunc={'fixed_drive':'count','drive_points': 'sum', 'drive_turnover': 'sum', 'drive_play_count': 'sum', 'drive_first_downs':'sum', 'drive_inside20':'sum',\\\n",
    "        'drive_yards_penalized':'sum'}).reset_index().sort_values(by=['season','week'], ascending=False)\n",
    "rz_data = drive_df.loc[drive_df['drive_inside20']==1].pivot_table(index=['season','week','posteam','defteam'], values=['drive_inside20','drive_points'], aggfunc='sum').reset_index().sort_values(by=[\\\n",
    "    'season','week'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total third and fourth downs\n",
    "off_yardage['third_down_total'] = off_yardage['third_down_converted'] + off_yardage['third_down_failed']\n",
    "off_yardage['fourth_down_total'] = off_yardage['fourth_down_converted'] + off_yardage['fourth_down_failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN WHEN YOU HAVE WIFI\n",
    "ids = nfl.import_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in passer id\n",
    "qbr['player_id'] = qbr['player_id'].astype(float)\n",
    "ids['espn_id'] = ids['espn_id'].astype(float)\n",
    "qbr = qbr.merge(ids[['espn_id','gsis_id']], how='left', left_on ='player_id', right_on='espn_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace team names\n",
    "qbr['team_abb'] = qbr['team_abb'].replace(replace_dict)\n",
    "qbr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a main df of all important info\n",
    "master = matchups.loc[matchups['season']>=2008][['game_id','season','week','away_team','away_score','home_team','home_score','result','location','total','away_rest','home_rest','away_moneyline',\\\n",
    "    'home_moneyline','spread_line','total_line','div_game','roof','surface','away_qb_id','home_qb_id','away_qb_name','home_qb_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through matchups in master and populate cols (features individually)\n",
    "master.loc[:,'home_elo'] = np.nan\n",
    "master.loc[:,'away_elo'] = np.nan\n",
    "master.loc[:,'home_pass_elo_off'] = np.nan # QB elo Def elo difference\n",
    "master.loc[:,'away_pass_elo_off'] = np.nan # QB elo Def elo difference\n",
    "master.loc[:,'home_pass_elo_def'] = np.nan # QB elo Def elo difference\n",
    "master.loc[:,'away_pass_elo_def'] = np.nan # QB elo Def elo difference\n",
    "master.loc[:,'home_rush_ypc'] = np.nan\n",
    "master.loc[:,'away_rush_ypc'] = np.nan\n",
    "master.loc[:,'home_rush_epa_play'] = np.nan\n",
    "master.loc[:,'away_rush_epa_play'] = np.nan\n",
    "master.loc[:,'home_qbr'] = np.nan\n",
    "master.loc[:,'away_qbr'] = np.nan\n",
    "master.loc[:,'home_epa_play'] = np.nan \n",
    "master.loc[:,'away_epa_play'] = np.nan \n",
    "master.loc[:,'home_epa_play_def'] = np.nan\n",
    "master.loc[:,'away_epa_play_def'] = np.nan\n",
    "master.loc[:,'home_yds_play'] = np.nan\n",
    "master.loc[:,'away_yds_play'] = np.nan\n",
    "master.loc[:,'home_yds_play_def'] = np.nan\n",
    "master.loc[:,'away_yds_play_def'] = np.nan\n",
    "master.loc[:,'home_3d_conv'] = np.nan\n",
    "master.loc[:,'away_3d_conv'] = np.nan\n",
    "master.loc[:,'home_3d_conv_def'] = np.nan\n",
    "master.loc[:,'away_3d_conv_def'] = np.nan\n",
    "master.loc[:,'home_4d_conv'] = np.nan\n",
    "master.loc[:,'away_4d_conv'] = np.nan\n",
    "master.loc[:,'home_4d_conv_def'] = np.nan\n",
    "master.loc[:,'away_4d_conv_def'] = np.nan\n",
    "master.loc[:,'home_1D_drive'] = np.nan\n",
    "master.loc[:,'away_1D_drive'] = np.nan\n",
    "master.loc[:,'home_1D_drive_def'] = np.nan\n",
    "master.loc[:,'away_1D_drive_def'] = np.nan\n",
    "master.loc[:,'home_RZ_drive'] = np.nan\n",
    "master.loc[:,'away_RZ_drive'] = np.nan\n",
    "master.loc[:,'home_RZ_drive_def'] = np.nan\n",
    "master.loc[:,'away_RZ_drive_def'] = np.nan\n",
    "master.loc[:,'home_play_drive'] = np.nan\n",
    "master.loc[:,'away_play_drive'] = np.nan\n",
    "master.loc[:,'home_play_drive_def'] = np.nan\n",
    "master.loc[:,'away_play_drive_def'] = np.nan\n",
    "master.loc[:,'home_points_drive'] = np.nan\n",
    "master.loc[:,'away_points_drive'] = np.nan\n",
    "master.loc[:,'home_points_drive_def'] = np.nan\n",
    "master.loc[:,'away_points_drive_def'] = np.nan\n",
    "master.loc[:,'home_to_drive'] = np.nan\n",
    "master.loc[:,'away_to_drive'] = np.nan\n",
    "master.loc[:,'home_to_drive_def'] = np.nan\n",
    "master.loc[:,'away_to_drive_def'] = np.nan\n",
    "master.loc[:,'home_pen_yds_drive'] = np.nan\n",
    "master.loc[:,'away_pen_yds_drive'] = np.nan\n",
    "master.loc[:,'home_pen_yds_drive_def'] = np.nan\n",
    "master.loc[:,'away_pen_yds_drive_def'] = np.nan\n",
    "master.loc[:,'home_points_RZ'] = np.nan\n",
    "master.loc[:,'away_points_RZ'] = np.nan\n",
    "master.loc[:,'home_points_RZ_def'] = np.nan\n",
    "master.loc[:,'away_points_RZ_def'] = np.nan\n",
    "\n",
    "# Change dtypes\n",
    "master['season'] = master['season'].astype(int)\n",
    "master['week'] = master['week'].astype(int)\n",
    "historical_elo_df['Season'] = historical_elo_df['Season'].astype(int)\n",
    "historical_elo_df['Week'] = historical_elo_df['Week'].astype(int)\n",
    "\n",
    "master = master.reset_index(drop=True)\n",
    "\n",
    "for i,row in master.iterrows():\n",
    "    # Populate elo differences\n",
    "    master.loc[i,'home_elo'], master.loc[i,'away_elo'] = get_elo(row['home_team'],row['season'],row['week'],historical_elo_df), get_elo(row['away_team'],row['season'],row['week'],historical_elo_df)\n",
    "        \n",
    "    master.loc[i,'home_pass_elo_off'], master.loc[i,'away_pass_elo_off'] = get_qb_elo(row['home_qb_id'],row['season'],row['week'],historical_elo_qb), get_qb_elo(row['away_qb_id'],row['season'],row['week'],historical_elo_qb)\n",
    "    \n",
    "    master.loc[i,'home_pass_elo_def'], master.loc[i,'away_pass_elo_def'] = get_elo(row['home_team'],row['season'],row['week'],historical_elo_def), get_elo(row['away_team'],row['season'],row['week'],historical_elo_def)\n",
    "    \n",
    "    # Populate other stats\n",
    "    master.loc[i,'home_rush_ypc'] = get_value(weekly_sum, row['season'], row['week'], row['home_team'], 'recent_team', 'rushing_yards', \\\n",
    "        'carries')\n",
    "    master.loc[i,'away_rush_ypc'] = get_value(weekly_sum, row['season'], \\\n",
    "        row['week'], row['away_team'], 'recent_team', 'rushing_yards', 'carries')\n",
    "    \n",
    "    master.loc[i,'home_rush_epa_play'] = get_value(weekly_sum, row['season'], row['week'], row['home_team'], 'recent_team', 'rushing_epa', \\\n",
    "        'carries') \n",
    "    master.loc[i,'away_rush_epa_play'] = get_value(weekly_sum, row['season'], \\\n",
    "        row['week'], row['away_team'], 'recent_team', 'rushing_epa', 'carries')\n",
    "    \n",
    "    master.loc[i,'home_qbr'] = get_qbr(qbr, row['season'], row['week'], row['home_qb_id'])\n",
    "    master.loc[i,'away_qbr'] = get_qbr(qbr, row['season'], row['week'], row['away_qb_id'])\n",
    "    \n",
    "    master.loc[i,'home_epa_play'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'posteam', 'epa', 'play')\n",
    "    master.loc[i,'away_epa_play'] = get_value(off_yardage, row['season'], row['week'], row['away_team'], 'posteam', 'epa', 'play')\n",
    "    \n",
    "    master.loc[i,'home_epa_play_def'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'defteam', 'epa', 'play')\n",
    "    master.loc[i,'away_epa_play_def'] = get_value(off_yardage, row['season'], row['week'], row['away_team'], 'defteam', 'epa', 'play')\n",
    "    \n",
    "    master.loc[i,'home_yds_play'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'posteam', 'yards_gained', 'play')\n",
    "    master.loc[i,'away_yds_play'] = get_value(off_yardage, row['season'], row['week'], row['away_team'], 'posteam', 'yards_gained', 'play')\n",
    "    \n",
    "    master.loc[i,'home_yds_play_def'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'defteam', 'yards_gained', 'play')\n",
    "    master.loc[i,'away_yds_play_def']= get_value(off_yardage, row['season'], row['week'], row['away_team'], 'defteam', 'yards_gained', 'play')\n",
    "    \n",
    "    master.loc[i,'home_3d_conv'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'posteam', 'third_down_converted', \\\n",
    "                                             'third_down_total')\n",
    "    master.loc[i,'away_3d_conv'] = get_value(off_yardage, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'third_down_converted', 'third_down_total')\n",
    "    \n",
    "    master.loc[i,'home_3d_conv_def'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'defteam', 'third_down_converted',\\\n",
    "                                                 'third_down_total') \n",
    "    master.loc[i,'away_3d_conv_def'] = get_value(off_yardage, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'third_down_converted', 'third_down_total')\n",
    "    \n",
    "    master.loc[i,'home_4d_conv'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'posteam', 'fourth_down_converted', \\\n",
    "                                             'fourth_down_total')\n",
    "    master.loc[i,'away_4d_conv'] = get_value(off_yardage, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'fourth_down_converted', 'fourth_down_total')\n",
    "    \n",
    "    master.loc[i,'home_4d_conv_def'] = get_value(off_yardage, row['season'], row['week'], row['home_team'], 'defteam', \\\n",
    "                                                 'fourth_down_converted', 'fourth_down_total') \n",
    "    master.loc[i,'away_4d_conv_def'] = get_value(off_yardage, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'fourth_down_converted', 'fourth_down_total')\n",
    "    \n",
    "    master.loc[i,'home_1D_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_first_downs', \\\n",
    "                                              'fixed_drive')\n",
    "    master.loc[i,'away_1D_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_first_downs', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_1D_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_first_downs', \\\n",
    "                                                  'fixed_drive')\n",
    "    master.loc[i,'away_1D_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_first_downs', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_RZ_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_inside20', \\\n",
    "                                              'fixed_drive')\n",
    "    master.loc[i,'away_RZ_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_inside20', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_RZ_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_inside20', \\\n",
    "                                                  'fixed_drive')\n",
    "    master.loc[i,'away_RZ_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_inside20', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_play_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_play_count', \\\n",
    "                                                'fixed_drive')\n",
    "    master.loc[i,'away_play_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_play_count', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_play_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_play_count', \\\n",
    "                                                    'fixed_drive')\n",
    "    master.loc[i,'away_play_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_play_count', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_points_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_points', \\\n",
    "                                                  'fixed_drive')\n",
    "    master.loc[i,'away_points_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_points', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_points_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_points', \\\n",
    "                                                      'fixed_drive')\n",
    "    master.loc[i,'away_points_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_points', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_to_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_turnover', \\\n",
    "                                                   'fixed_drive')\n",
    "    master.loc[i,'away_to_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_turnover', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_to_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_turnover',\\\n",
    "                                                   'fixed_drive')\n",
    "    master.loc[i,'away_to_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_turnover', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_pen_yds_drive'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'posteam', \\\n",
    "                                                   'drive_yards_penalized', 'fixed_drive')\n",
    "    master.loc[i,'away_pen_yds_drive'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_yards_penalized', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_pen_yds_drive_def'] = get_value(drive_data, row['season'], row['week'], row['home_team'], 'defteam', \\\n",
    "                                                       'drive_yards_penalized', 'fixed_drive')\n",
    "    master.loc[i,'away_pen_yds_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_yards_penalized', 'fixed_drive')\n",
    "    \n",
    "    master.loc[i,'home_points_RZ'] = get_value(rz_data, row['season'], row['week'], row['home_team'], 'posteam', 'drive_points', \\\n",
    "                                               'drive_inside20')\n",
    "    master.loc[i,'away_points_RZ'] = get_value(rz_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'posteam', 'drive_points', 'drive_inside20')\n",
    "    \n",
    "    master.loc[i,'home_points_RZ_def'] = get_value(rz_data, row['season'], row['week'], row['home_team'], 'defteam', 'drive_points', \\\n",
    "                                                   'drive_inside20')\n",
    "    master.loc[i,'away_points_RZ_def'] = get_value(rz_data, row['season'], \\\n",
    "        row['week'], row['away_team'], 'defteam', 'drive_points', 'drive_inside20')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary col to indicate win\n",
    "master.loc[:,'is_home_win'] = np.where(master.result>0, 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a col if game is in dome\n",
    "master.loc[:,'is_dome'] = np.where(master['roof']=='dome', 1.0, 0.0)\n",
    "\n",
    "# Create a col if game is played on natural grass\n",
    "master.loc[:,'is_grass'] = np.where(master['surface']=='grass',1.0,0.0)\n",
    "\n",
    "# Create a col if game is played at neutral site\n",
    "master.loc[:,'is_neutral'] = np.where(master['location']=='Neutral',1.0,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv('matchups_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loss = master.loc[master['is_home_win']==0.0]\n",
    "data_win = master.loc[master['is_home_win']==1.0]\n",
    "sns.distplot(data_loss.yds_play_diff.dropna(),kde=False,label='Loss')\n",
    "sns.distplot(data_win.yds_play_diff.dropna(),kde=False,label='Win')\n",
    "plt.legend()\n",
    "plt.title('yds_play_diff histogram')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss, mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBClassifier\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_model(mdl, X_train, X_val, y_train, y_val, type='regressor'):\n",
    "    \n",
    "    # Write some code to fit the model, and calculate evaluation metrics on\n",
    "    # the validation set.\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Fit the model\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_pred = mdl.predict(X_val)\n",
    "    if type == 'classifier':\n",
    "        y_proba = mdl.predict_proba(X_val) # For log_loss and roc_auc_score\n",
    "        \n",
    "        # Calculate various classification metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        roc_auc = roc_auc_score(y_val, y_proba[:, 1])  # Assuming binary classification\n",
    "        logloss = log_loss(y_val, y_proba)\n",
    "        \n",
    "        # -------------------------------------------------------------------------\\\n",
    "        print('The precision score is {} and the recall score is {}'.format(precision, recall))\n",
    "        return accuracy, precision, recall, f1, roc_auc, logloss\n",
    "        \n",
    "    else:\n",
    "        train_score = mdl.score(X_train, y_train)\n",
    "        test_score = mdl.score(X_val, y_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # -------------------------------------------------------------------------\\\n",
    "        print('The train score is {} and the test score is {}'.format(train_score, test_score))\n",
    "        return train_score, test_score, mae, mse, rmse\n",
    "    \n",
    "\n",
    "def get_feature_importances(mdl, X_train):\n",
    "    # Create an explainer object for the XGBoost model\n",
    "    explainer = shap.Explainer(mdl)\n",
    "\n",
    "    # Calculate SHAP values for all features in the training data\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "    # Summarize the SHAP values to obtain feature importances\n",
    "    feature_importances = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "    # Get the corresponding feature names\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Sort the feature importances in descending order\n",
    "    sorted_indices = feature_importances.argsort()[::-1]\n",
    "    sorted_importances = feature_importances[sorted_indices]\n",
    "    sorted_feature_names = feature_names[sorted_indices]\n",
    "\n",
    "    # Print the feature importances\n",
    "    for feature_name, importance in zip(sorted_feature_names, sorted_importances):\n",
    "        print(f\"{feature_name}: {importance}\")\n",
    "\n",
    "    # Plot the feature importances\n",
    "    shap.summary_plot(shap_values, X_train, feature_names=feature_names)\n",
    "\n",
    "def print_heavily_correlated_features(df, threshold=0.7):\n",
    "    corr = df.corr().abs()\n",
    "    corr = corr[corr > threshold]\n",
    "    print(corr.count().sort_values(ascending=False) - 1)\n",
    "\n",
    "## Function to discover interacting features to engineer\n",
    "def discover_interactions(interactiondf, target, function, threshold):\n",
    "    # Looking for interaction effects within features by dividing\n",
    "    base_corrs = interactiondf.corr()[target].drop(index=target)\n",
    "\n",
    "    for feature1 in base_corrs.index:\n",
    "        for feature2 in base_corrs.index:\n",
    "            if feature2 != feature1:\n",
    "                # divide the two features to create a new feature\n",
    "                if function == 'divide':\n",
    "                    new_feature = interactiondf[feature1] / interactiondf[feature2]\n",
    "                else:\n",
    "                    new_feature = interactiondf[feature1] * interactiondf[feature2]\n",
    "                new_corr = np.abs(np.round(np.corrcoef(new_feature, interactiondf[target])[0,1], 3))\n",
    "                corr1 = np.abs(np.round(base_corrs[feature1], 3))\n",
    "                corr2 = np.abs(np.round(base_corrs[feature2], 3))\n",
    "                # add a threshold of 0.02 to make sure that the improvement is meaningful\n",
    "                if new_corr > max(corr1, corr2)+0.02:\n",
    "                    # Only show significant correlations\n",
    "                    if new_corr >= threshold:\n",
    "                        print('{} {} combine to get correlation {} compared to {} {}'.format(\n",
    "                            feature1, feature2, new_corr, corr1, corr2))\n",
    "\n",
    "def run_randomized_search(X_train, y_train, n_iter=10, feature_constraints=None):\n",
    "    # Retrained with grid search\n",
    "    if feature_constraints == None:\n",
    "        mdl = XGBClassifier()\n",
    "    else:\n",
    "        mdl = XGBClassifier(monotone_constraints=feature_constraints)\n",
    "\n",
    "    params_to_search = {\n",
    "        'learning_rate': [0.05, 0.0625, 0.1],\n",
    "        'gamma': [0,0.1,0.2,0.3],\n",
    "        'max_depth': [5,6,7,8],\n",
    "        'n_estimators': [250,375,500],\n",
    "        'reg_lambda': [0, 0.1, 1, 10]\n",
    "    }\n",
    "\n",
    "    optimized_dt = RandomizedSearchCV(mdl, params_to_search, scoring = 'neg_log_loss', refit=True, cv=5, n_iter=n_iter, random_state=42)\n",
    "\n",
    "    optimized_dt.fit(X_train, y_train)\n",
    "    \n",
    "    return optimized_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('matchups_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['away_rest','home_rest','spread_line','total_line','div_game','home_elo', 'away_elo','home_pass_elo_off','away_pass_elo_off',\n",
    "            'home_pass_elo_def','away_pass_elo_def','home_rush_ypc','away_rush_ypc','home_rush_epa_play','away_rush_epa_play','home_qbr','away_qbr',\n",
    "            'home_epa_play','away_epa_play','home_epa_play_def','away_epa_play_def','home_yds_play','away_yds_play','home_yds_play_def',\n",
    "            'away_yds_play_def','home_3d_conv','away_3d_conv','home_3d_conv_def','away_3d_conv_def','home_4d_conv',\n",
    "            'away_4d_conv','home_4d_conv_def','away_4d_conv_def','home_1D_drive','away_1D_drive','home_1D_drive_def','away_1D_drive_def',\n",
    "            'home_points_drive','away_points_drive','home_points_drive_def','away_points_drive_def','home_to_drive',\n",
    "            'away_to_drive','home_to_drive_def','away_to_drive_def','home_pen_yds_drive','away_pen_yds_drive','home_pen_yds_drive_def',\n",
    "            'away_pen_yds_drive_def','home_points_RZ','away_points_RZ','home_points_RZ_def','away_points_RZ_def','is_dome','is_grass']\n",
    "\n",
    "# ['home_RZ_drive','away_RZ_drive','home_RZ_drive_def','away_RZ_drive_def','home_play_drive','away_play_drive','home_play_drive_def',\n",
    "#  'away_play_drive_def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = master[master.season<2020]\n",
    "interactiondf = df_train[sorted(features) + ['is_home_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discover_interactions(interactiondf, 'is_home_win', 'divide', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactiondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "df_train = master[master.season<2020]\n",
    "df_test = master[master.season>=2020]\n",
    "\n",
    "# Write your code here.\n",
    "# Partition the training data into features and target\n",
    "X_train = df_train[sorted(features)]\n",
    "y_train = df_train.is_home_win\n",
    "\n",
    "# Partition the testing data into features and target\n",
    "X_test = df_test[sorted(features)]\n",
    "y_test = df_test.is_home_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_heavily_correlated_features(X_train, threshold=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr().loc['away_RZ_drive',:].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train basic xgboost classifier\n",
    "mdl = XGBClassifier()\n",
    "fit_and_score_model(mdl, X_train, X_test, y_train, y_test, type='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your monotonic constraints as a dictionary\n",
    "feature_constraints = {}\n",
    "feature_constraints['home_3d_conv_def'] = -1  # Negative constraint for 'home_3d_conv_def'\n",
    "feature_constraints['away_3d_conv_def'] = -1  # Negative constraint for 'away_3d_conv_def'\n",
    "\n",
    "# Create and train your XGBoost model while specifying the monotonic_constraints parameter\n",
    "mdl = XGBClassifier(\n",
    "    monotone_constraints=feature_constraints,  # Set the monotonic constraints\n",
    "    objective='binary:logistic',  # Use 'binary:logistic' for binary classification\n",
    ")\n",
    "fit_and_score_model(mdl, X_train, X_test, y_train, y_test, type='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your monotonic constraints as a dictionary\n",
    "feature_constraints = {}\n",
    "feature_constraints['home_3d_conv_def'] = -1  # Negative constraint for home team's chances\n",
    "feature_constraints['away_3d_conv_def'] = 1  # Positive constraint for home team's chances \n",
    "feature_constraints['home_yds_play'] = 1 \n",
    "feature_constraints['away_yds_play'] = -1  \n",
    "feature_constraints['home_to_drive_def'] = 1 \n",
    "feature_constraints['away_to_drive_def'] = -1  \n",
    "feature_constraints['home_points_RZ_def'] = -1 \n",
    "feature_constraints['away_points_RZ_def'] = 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_mdl = run_randomized_search(X_train, y_train, n_iter=10, feature_constraints=feature_constraints)\n",
    "mdl = optimized_mdl.best_estimator_\n",
    "fit_and_score_model(mdl, X_train, X_test, y_train, y_test, type='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''(0.6372315035799523,\n",
    " 0.6525612472160356,\n",
    " 0.6643990929705216,\n",
    " 0.6584269662921348,\n",
    " 0.6979386212923456,\n",
    " 0.6832563014459843)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_importances(mdl, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = mdl.predict(X_test)\n",
    "cfm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "ax = sns.heatmap(cfm, annot=True)\n",
    "ax.set(xlabel='Predicted', ylabel='Actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(mdl,'NFL_2023_game_prediction.jlb')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = joblib.load('NFL_2023_game_prediction.jlb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually imported sheet of starters\n",
    "starters = pd.read_csv('starting_qbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming = nfl.import_schedules([2023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in starting QB\n",
    "upcoming = upcoming.drop(['away_qb_id','home_qb_id','away_qb_name','home_qb_name'],axis=1)\n",
    "\n",
    "upcoming = upcoming.merge(starters[['Team','passer','passer_id']], how='left', left_on='home_team', right_on='Team').rename({'passer':\\\n",
    "    'home_qb_name', 'passer_id':'home_qb_id'},axis=1)\n",
    "\n",
    "upcoming = upcoming.drop(['Team'],axis=1)\n",
    "\n",
    "upcoming = upcoming.merge(starters[['Team','passer','passer_id']], how='left', left_on='away_team', right_on='Team').rename({'passer':\\\n",
    "    'away_qb_name', 'passer_id':'away_qb_id'},axis=1)\n",
    "\n",
    "upcoming = upcoming.drop(['Team'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab a main df of all important info\n",
    "newseason = upcoming[['game_id','season','week','away_team','away_score','home_team','home_score','result','location','total','away_rest','home_rest','away_moneyline',\\\n",
    "    'home_moneyline','spread_line','total_line','div_game','roof','surface','away_qb_id','home_qb_id','away_qb_name','home_qb_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_elo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean Elo at the end of the season\n",
    "mean_elo = calculate_mean_elo(elo_df)\n",
    "\n",
    "# Regress each team's Elo ratings towards the mean\n",
    "elo_df = regress_to_mean(elo_df, mean_elo, regression_weight=1/3)\n",
    "\n",
    "elo_df_temp = elo_df.copy()\n",
    "\n",
    "elo_df_temp['Week'] = 0\n",
    "elo_df_temp['Season'] = newseason.loc[0,'season']\n",
    "\n",
    "historical_elo_df = pd.concat([historical_elo_df,elo_df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean Elo at the end of the season\n",
    "mean_elo = calculate_mean_elo(elo_def)\n",
    "\n",
    "# Regress each team's Elo ratings towards the mean\n",
    "elo_def = regress_to_mean(elo_def, mean_elo, regression_weight=1/3)\n",
    "\n",
    "elo_def_temp = elo_def.copy()\n",
    "\n",
    "elo_def_temp['Week'] = 0\n",
    "elo_def_temp['Season'] = newseason.loc[0,'season']\n",
    "\n",
    "historical_elo_def = pd.concat([historical_elo_def,elo_def_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through matchups in master and populate cols (features individually)\n",
    "newseason.loc[:,'home_elo'] = np.nan\n",
    "newseason.loc[:,'away_elo'] = np.nan\n",
    "newseason.loc[:,'home_pass_elo_off'] = np.nan # QB elo Def elo difference\n",
    "newseason.loc[:,'away_pass_elo_off'] = np.nan # QB elo Def elo difference\n",
    "newseason.loc[:,'home_pass_elo_def'] = np.nan # QB elo Def elo difference\n",
    "newseason.loc[:,'away_pass_elo_def'] = np.nan # QB elo Def elo difference\n",
    "newseason.loc[:,'home_rush_ypc'] = np.nan\n",
    "newseason.loc[:,'away_rush_ypc'] = np.nan\n",
    "newseason.loc[:,'home_rush_epa_play'] = np.nan\n",
    "newseason.loc[:,'away_rush_epa_play'] = np.nan\n",
    "newseason.loc[:,'home_qbr'] = np.nan\n",
    "newseason.loc[:,'away_qbr'] = np.nan\n",
    "newseason.loc[:,'home_epa_play'] = np.nan \n",
    "newseason.loc[:,'away_epa_play'] = np.nan \n",
    "newseason.loc[:,'home_epa_play_def'] = np.nan\n",
    "newseason.loc[:,'away_epa_play_def'] = np.nan\n",
    "newseason.loc[:,'home_yds_play'] = np.nan\n",
    "newseason.loc[:,'away_yds_play'] = np.nan\n",
    "newseason.loc[:,'home_yds_play_def'] = np.nan\n",
    "newseason.loc[:,'away_yds_play_def'] = np.nan\n",
    "newseason.loc[:,'home_3d_conv'] = np.nan\n",
    "newseason.loc[:,'away_3d_conv'] = np.nan\n",
    "newseason.loc[:,'home_3d_conv_def'] = np.nan\n",
    "newseason.loc[:,'away_3d_conv_def'] = np.nan\n",
    "newseason.loc[:,'home_4d_conv'] = np.nan\n",
    "newseason.loc[:,'away_4d_conv'] = np.nan\n",
    "newseason.loc[:,'home_4d_conv_def'] = np.nan\n",
    "newseason.loc[:,'away_4d_conv_def'] = np.nan\n",
    "newseason.loc[:,'home_1D_drive'] = np.nan\n",
    "newseason.loc[:,'away_1D_drive'] = np.nan\n",
    "newseason.loc[:,'home_1D_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_1D_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_RZ_drive'] = np.nan\n",
    "newseason.loc[:,'away_RZ_drive'] = np.nan\n",
    "newseason.loc[:,'home_RZ_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_RZ_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_play_drive'] = np.nan\n",
    "newseason.loc[:,'away_play_drive'] = np.nan\n",
    "newseason.loc[:,'home_play_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_play_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_points_drive'] = np.nan\n",
    "newseason.loc[:,'away_points_drive'] = np.nan\n",
    "newseason.loc[:,'home_points_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_points_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_to_drive'] = np.nan\n",
    "newseason.loc[:,'away_to_drive'] = np.nan\n",
    "newseason.loc[:,'home_to_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_to_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_pen_yds_drive'] = np.nan\n",
    "newseason.loc[:,'away_pen_yds_drive'] = np.nan\n",
    "newseason.loc[:,'home_pen_yds_drive_def'] = np.nan\n",
    "newseason.loc[:,'away_pen_yds_drive_def'] = np.nan\n",
    "newseason.loc[:,'home_points_RZ'] = np.nan\n",
    "newseason.loc[:,'away_points_RZ'] = np.nan\n",
    "newseason.loc[:,'home_points_RZ_def'] = np.nan\n",
    "newseason.loc[:,'away_points_RZ_def'] = np.nan\n",
    "\n",
    "# Change dtypes\n",
    "newseason['season'] = newseason['season'].astype(int)\n",
    "newseason['week'] = newseason['week'].astype(int)\n",
    "historical_elo_df['Season'] = historical_elo_df['Season'].astype(int)\n",
    "historical_elo_df['Week'] = historical_elo_df['Week'].astype(int)\n",
    "\n",
    "newseason = newseason.reset_index(drop=True)\n",
    "\n",
    "current_week = newseason.loc[0,'week']\n",
    "\n",
    "for i,row in newseason.iterrows():\n",
    "    # Populate elo differences\n",
    "    newseason.loc[i,'home_elo'], newseason.loc[i,'away_elo'] = get_elo(row['home_team'],row['season'],current_week,historical_elo_df), get_elo(row['away_team'],row['season'],current_week,historical_elo_df)\n",
    "        \n",
    "    newseason.loc[i,'home_pass_elo_off'], newseason.loc[i,'away_pass_elo_off'] = get_qb_elo(row['home_qb_id'],row['season'],current_week,historical_elo_qb), get_qb_elo(row['away_qb_id'],row['season'],current_week,historical_elo_qb)\n",
    "    \n",
    "    newseason.loc[i,'home_pass_elo_def'], newseason.loc[i,'away_pass_elo_def'] = get_elo(row['home_team'],row['season'],current_week,historical_elo_def), get_elo(row['away_team'],row['season'],current_week,historical_elo_def)\n",
    "    \n",
    "    # Populate other stats\n",
    "    newseason.loc[i,'home_rush_ypc'] = get_value(weekly_sum, row['season'], current_week, row['home_team'], 'recent_team', 'rushing_yards', \\\n",
    "        'carries')\n",
    "    newseason.loc[i,'away_rush_ypc'] = get_value(weekly_sum, row['season'], \\\n",
    "        current_week, row['away_team'], 'recent_team', 'rushing_yards', 'carries')\n",
    "    \n",
    "    newseason.loc[i,'home_rush_epa_play'] = get_value(weekly_sum, row['season'], current_week, row['home_team'], 'recent_team', 'rushing_epa', \\\n",
    "        'carries') \n",
    "    newseason.loc[i,'away_rush_epa_play'] = get_value(weekly_sum, row['season'], \\\n",
    "        current_week, row['away_team'], 'recent_team', 'rushing_epa', 'carries')\n",
    "    \n",
    "    newseason.loc[i,'home_qbr'] = get_qbr(qbr, row['season'], current_week, row['home_qb_id'])\n",
    "    newseason.loc[i,'away_qbr'] = get_qbr(qbr, row['season'], current_week, row['away_qb_id'])\n",
    "    \n",
    "    newseason.loc[i,'home_epa_play'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'posteam', 'epa', 'play')\n",
    "    newseason.loc[i,'away_epa_play'] = get_value(off_yardage, row['season'], current_week, row['away_team'], 'posteam', 'epa', 'play')\n",
    "    \n",
    "    newseason.loc[i,'home_epa_play_def'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'defteam', 'epa', 'play')\n",
    "    newseason.loc[i,'away_epa_play_def'] = get_value(off_yardage, row['season'], current_week, row['away_team'], 'defteam', 'epa', 'play')\n",
    "    \n",
    "    newseason.loc[i,'home_yds_play'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'posteam', 'yards_gained', 'play')\n",
    "    newseason.loc[i,'away_yds_play'] = get_value(off_yardage, row['season'], current_week, row['away_team'], 'posteam', 'yards_gained', 'play')\n",
    "    \n",
    "    newseason.loc[i,'home_yds_play_def'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'defteam', 'yards_gained', 'play')\n",
    "    newseason.loc[i,'away_yds_play_def']= get_value(off_yardage, row['season'], current_week, row['away_team'], 'defteam', 'yards_gained', 'play')\n",
    "    \n",
    "    newseason.loc[i,'home_3d_conv'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'posteam', 'third_down_converted', \\\n",
    "                                             'third_down_total')\n",
    "    newseason.loc[i,'away_3d_conv'] = get_value(off_yardage, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'third_down_converted', 'third_down_total')\n",
    "    \n",
    "    newseason.loc[i,'home_3d_conv_def'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'defteam', 'third_down_converted',\\\n",
    "                                                 'third_down_total') \n",
    "    newseason.loc[i,'away_3d_conv_def'] = get_value(off_yardage, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'third_down_converted', 'third_down_total')\n",
    "    \n",
    "    newseason.loc[i,'home_4d_conv'] = get_value(off_yardage, row['season'], current_week, row['home_team'], 'posteam', 'fourth_down_converted', \\\n",
    "                                             'fourth_down_total')\n",
    "    newseason.loc[i,'away_4d_conv'] = get_value(off_yardage, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'fourth_down_converted', 'fourth_down_total')\n",
    "    \n",
    "    newseason.loc[i,'home_4d_conv_def'] = get_value(off_yardage, row['season'],current_week, row['home_team'], 'defteam', \\\n",
    "                                                 'fourth_down_converted', 'fourth_down_total') \n",
    "    newseason.loc[i,'away_4d_conv_def'] = get_value(off_yardage, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'fourth_down_converted', 'fourth_down_total')\n",
    "    \n",
    "    newseason.loc[i,'home_1D_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_first_downs', \\\n",
    "                                              'fixed_drive')\n",
    "    newseason.loc[i,'away_1D_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_first_downs', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_1D_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_first_downs', \\\n",
    "                                                  'fixed_drive')\n",
    "    newseason.loc[i,'away_1D_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_first_downs', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_RZ_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_inside20', \\\n",
    "                                              'fixed_drive')\n",
    "    newseason.loc[i,'away_RZ_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_inside20', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_RZ_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_inside20', \\\n",
    "                                                  'fixed_drive')\n",
    "    newseason.loc[i,'away_RZ_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_inside20', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_play_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_play_count', \\\n",
    "                                                'fixed_drive')\n",
    "    newseason.loc[i,'away_play_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_play_count', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_play_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_play_count', \\\n",
    "                                                    'fixed_drive')\n",
    "    newseason.loc[i,'away_play_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_play_count', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_points_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_points', \\\n",
    "                                                  'fixed_drive')\n",
    "    newseason.loc[i,'away_points_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_points', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_points_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_points', \\\n",
    "                                                      'fixed_drive')\n",
    "    newseason.loc[i,'away_points_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_points', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_to_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_turnover', \\\n",
    "                                                   'fixed_drive')\n",
    "    newseason.loc[i,'away_to_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_turnover', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_to_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_turnover',\\\n",
    "                                                   'fixed_drive')\n",
    "    newseason.loc[i,'away_to_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_turnover', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_pen_yds_drive'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'posteam', \\\n",
    "                                                   'drive_yards_penalized', 'fixed_drive')\n",
    "    newseason.loc[i,'away_pen_yds_drive'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_yards_penalized', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_pen_yds_drive_def'] = get_value(drive_data, row['season'], current_week, row['home_team'], 'defteam', \\\n",
    "                                                       'drive_yards_penalized', 'fixed_drive')\n",
    "    newseason.loc[i,'away_pen_yds_drive_def'] = get_value(drive_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_yards_penalized', 'fixed_drive')\n",
    "    \n",
    "    newseason.loc[i,'home_points_RZ'] = get_value(rz_data, row['season'], current_week, row['home_team'], 'posteam', 'drive_points', \\\n",
    "                                               'drive_inside20')\n",
    "    newseason.loc[i,'away_points_RZ'] = get_value(rz_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'posteam', 'drive_points', 'drive_inside20')\n",
    "    \n",
    "    newseason.loc[i,'home_points_RZ_def'] = get_value(rz_data, row['season'], current_week, row['home_team'], 'defteam', 'drive_points', \\\n",
    "                                                   'drive_inside20')\n",
    "    newseason.loc[i,'away_points_RZ_def'] = get_value(rz_data, row['season'], \\\n",
    "        current_week, row['away_team'], 'defteam', 'drive_points', 'drive_inside20')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a col if game is in dome\n",
    "newseason.loc[:,'is_dome'] = np.where(newseason['roof']=='dome', 1.0, 0.0)\n",
    "\n",
    "# Create a col if game is played on natural grass\n",
    "newseason.loc[:,'is_grass'] = np.where(newseason['surface']=='grass',1.0,0.0)\n",
    "\n",
    "# Create a col if game is played at neutral site\n",
    "newseason.loc[:,'is_neutral'] = np.where(newseason['location']=='Neutral',1.0,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason.loc[0:31,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = newseason[sorted(features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = mdl.predict_proba(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason['home_team_win_prob'] = y_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason.groupby(['home_team'])['home_team_win_prob'].sum().reset_index().sort_values(by='home_team_win_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason.loc[0:31,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseason.to_csv('NFL_2023_week1_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
